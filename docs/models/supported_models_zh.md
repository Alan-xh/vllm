---
title: æ”¯æŒçš„æ¨¡å‹
---
[](){ #supported-models }

vLLM æ”¯æŒå¤šç§ä»»åŠ¡çš„ [ç”Ÿæˆæ¨¡å‹](./generative_models.md) å’Œ [æ± åŒ–æ¨¡å‹](./pooling_models.md)ã€‚
å¦‚æœä¸€ä¸ªæ¨¡å‹æ”¯æŒå¤šä¸ªä»»åŠ¡ï¼Œå¯ä»¥é€šè¿‡ `--task` å‚æ•°è®¾ç½®ä»»åŠ¡ç±»å‹ã€‚

å¯¹äºæ¯ç§ä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ—å‡ºäº† vLLM ä¸­å·²å®ç°çš„æ¨¡å‹æ¶æ„ã€‚
åœ¨æ¯ä¸ªæ¶æ„æ—è¾¹ï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†ä¸€äº›ä½¿ç”¨è¯¥æ¶æ„çš„çƒ­é—¨æ¨¡å‹ã€‚

## æ¨¡å‹å®ç°

### vLLM

å¦‚æœ vLLM åŸç”Ÿæ”¯æŒæŸä¸ªæ¨¡å‹ï¼Œå…¶å®ç°å¯ä»¥åœ¨ <gh-file:vllm/model_executor/models> ä¸­æ‰¾åˆ°ã€‚

è¿™äº›æ¨¡å‹æ˜¯æˆ‘ä»¬åˆ—åœ¨ [æ”¯æŒçš„æ–‡æœ¬æ¨¡å‹][supported-text-models] å’Œ [æ”¯æŒçš„å¤šæ¨¡æ€æ¨¡å‹][supported-mm-models] ä¸­çš„æ¨¡å‹ã€‚

[](){ #transformers-backend }

### Transformers

vLLM è¿˜æ”¯æŒ Transformers ä¸­å¯ç”¨çš„æ¨¡å‹å®ç°ã€‚ç›®å‰å¹¶éæ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒï¼Œä½†å¤§å¤šæ•°è§£ç å™¨è¯­è¨€æ¨¡å‹éƒ½å—æ”¯æŒï¼Œè§†è§‰è¯­è¨€æ¨¡å‹çš„æ”¯æŒä¹Ÿåœ¨è®¡åˆ’ä¸­ï¼

è¦æ£€æŸ¥æ¨¡å‹åç«¯æ˜¯å¦ä¸º Transformersï¼Œå¯ä»¥ç®€å•åœ°æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š

```python
from vllm import LLM
llm = LLM(model=..., task="generate")  # ä½ çš„æ¨¡å‹åç§°æˆ–è·¯å¾„
llm.apply_model(lambda model: print(type(model)))
```

å¦‚æœè¾“å‡ºä¸º `TransformersForCausalLM`ï¼Œåˆ™è¡¨ç¤ºè¯¥æ¨¡å‹åŸºäº Transformersï¼

!!! tip
    ä½ å¯ä»¥é€šè¿‡è®¾ç½® `model_impl="transformers"`ï¼ˆç”¨äº [ç¦»çº¿æ¨ç†][offline-inference]ï¼‰æˆ– `--model-impl transformers`ï¼ˆç”¨äº [OpenAI å…¼å®¹æœåŠ¡å™¨][openai-compatible-server]ï¼‰æ¥å¼ºåˆ¶ä½¿ç”¨ `TransformersForCausalLM`ã€‚

!!! note
    vLLM å¯èƒ½æ— æ³•å®Œå…¨ä¼˜åŒ– Transformers å®ç°ï¼Œå› æ­¤ä¸ vLLM åŸç”Ÿæ¨¡å‹ç›¸æ¯”ï¼Œä½¿ç”¨ Transformers æ¨¡å‹æ—¶æ€§èƒ½å¯èƒ½ä¼šä¸‹é™ã€‚

#### è‡ªå®šä¹‰æ¨¡å‹

å¦‚æœä¸€ä¸ªæ¨¡å‹æ—¢ä¸è¢« vLLM åŸç”Ÿæ”¯æŒï¼Œä¹Ÿä¸è¢« Transformers æ”¯æŒï¼Œå®ƒä»ç„¶å¯ä»¥åœ¨ vLLM ä¸­ä½¿ç”¨ï¼

è¦ä½¿æ¨¡å‹ä¸ vLLM çš„ Transformers åç«¯å…¼å®¹ï¼Œæ¨¡å‹å¿…é¡»ï¼š

- æ˜¯ä¸€ä¸ªä¸ Transformers å…¼å®¹çš„è‡ªå®šä¹‰æ¨¡å‹ï¼ˆå‚è§ [Transformers - è‡ªå®šä¹‰æ¨¡å‹](https://huggingface.co/docs/transformers/en/custom_models)ï¼‰ï¼š
    * æ¨¡å‹ç›®å½•å¿…é¡»å…·æœ‰æ­£ç¡®çš„ç»“æ„ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å« `config.json` æ–‡ä»¶ï¼‰ã€‚
    * `config.json` å¿…é¡»åŒ…å« `auto_map.AutoModel`ã€‚
- æ˜¯ä¸€ä¸ªä¸ vLLM çš„ Transformers åç«¯å…¼å®¹çš„æ¨¡å‹ï¼ˆå‚è§ [ç¼–å†™è‡ªå®šä¹‰æ¨¡å‹][writing-custom-models]ï¼‰ï¼š
    * è‡ªå®šä¹‰åº”åœ¨åŸºç¡€æ¨¡å‹ä¸­å®Œæˆï¼ˆä¾‹å¦‚ï¼Œåœ¨ `MyModel` ä¸­ï¼Œè€Œä¸æ˜¯ `MyModelForCausalLM` ä¸­ï¼‰ã€‚

å¦‚æœå…¼å®¹æ¨¡å‹ï¼š

- åœ¨ Hugging Face æ¨¡å‹ä¸­å¿ƒï¼Œåªéœ€ä¸º [ç¦»çº¿æ¨ç†][offline-inference] è®¾ç½® `trust_remote_code=True`ï¼Œæˆ–ä¸º [OpenAI å…¼å®¹æœåŠ¡å™¨][openai-compatible-server] è®¾ç½® `--trust-remote-code`ã€‚
- åœ¨æœ¬åœ°ç›®å½•ä¸­ï¼Œåªéœ€å°†ç›®å½•è·¯å¾„ä¼ é€’ç»™ `model=<MODEL_DIR>`ï¼ˆç”¨äº [ç¦»çº¿æ¨ç†][offline-inference]ï¼‰æˆ– `vllm serve <MODEL_DIR>`ï¼ˆç”¨äº [OpenAI å…¼å®¹æœåŠ¡å™¨][openai-compatible-server]ï¼‰ã€‚

è¿™æ„å‘³ç€ï¼Œé€šè¿‡ vLLM çš„ Transformers åç«¯ï¼Œæ–°æ¨¡å‹å¯ä»¥åœ¨ Transformers æˆ– vLLM æ­£å¼æ”¯æŒä¹‹å‰ä½¿ç”¨ï¼

[](){ #writing-custom-models }

#### ç¼–å†™è‡ªå®šä¹‰æ¨¡å‹

æœ¬èŠ‚è¯¦ç»†ä»‹ç»äº†å¦‚ä½•å¯¹ä¸ Transformers å…¼å®¹çš„è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œå¿…è¦ä¿®æ”¹ï¼Œä½¿å…¶ä¸ vLLM çš„ Transformers åç«¯å…¼å®¹ã€‚ï¼ˆæˆ‘ä»¬å‡è®¾å·²ç»åˆ›å»ºäº†ä¸€ä¸ªä¸ Transformers å…¼å®¹çš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œå‚è§ [Transformers - è‡ªå®šä¹‰æ¨¡å‹](https://huggingface.co/docs/transformers/en/custom_models)ï¼‰ã€‚

è¦ä½¿æ¨¡å‹ä¸ Transformers åç«¯å…¼å®¹ï¼Œéœ€è¦ï¼š

1. ä» `MyModel` åˆ° `MyAttention` çš„æ‰€æœ‰æ¨¡å—éƒ½ä¼ é€’ `kwargs`ã€‚
2. `MyAttention` å¿…é¡»ä½¿ç”¨ `ALL_ATTENTION_FUNCTIONS` è°ƒç”¨æ³¨æ„åŠ›æœºåˆ¶ã€‚
3. `MyModel` å¿…é¡»åŒ…å« `_supports_attention_backend = True`ã€‚

```python title="modeling_my_model.py"

from transformers import PreTrainedModel
from torch import nn

class MyAttention(nn.Module):

    def forward(self, hidden_states, **kwargs):
        ...
        attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]
        attn_output, attn_weights = attention_interface(
            self,
            query_states,
            key_states,
            value_states,
            **kwargs,
        )
        ...

class MyModel(PreTrainedModel):
    _supports_attention_backend = True
```

ä»¥ä¸‹æ˜¯åŠ è½½æ­¤æ¨¡å‹æ—¶åå°å‘ç”Ÿçš„äº‹æƒ…ï¼š

1. åŠ è½½é…ç½®ã€‚
2. ä»é…ç½®ä¸­çš„ `auto_map` åŠ è½½ `MyModel` Python ç±»ï¼Œå¹¶æ£€æŸ¥æ¨¡å‹æ˜¯å¦ `is_backend_compatible()`ã€‚
3. å°† `MyModel` åŠ è½½åˆ° `TransformersForCausalLM` ä¸­ï¼ˆå‚è§ <gh-file:vllm/model_executor/models/transformers.py>ï¼‰ï¼Œå®ƒä¼šè®¾ç½® `self.config._attn_implementation = "vllm"`ï¼Œä»¥ä½¿ç”¨ vLLM çš„æ³¨æ„åŠ›å±‚ã€‚

å°±è¿™æ ·ï¼

è¦ä½¿ä½ çš„æ¨¡å‹ä¸ vLLM çš„å¼ é‡å¹¶è¡Œå’Œ/æˆ–æµæ°´çº¿å¹¶è¡ŒåŠŸèƒ½å…¼å®¹ï¼Œä½ å¿…é¡»åœ¨æ¨¡å‹çš„é…ç½®ç±»ä¸­æ·»åŠ  `base_model_tp_plan` å’Œ/æˆ– `base_model_pp_plan`ï¼š

```python title="configuration_my_model.py"

from transformers import PretrainedConfig

class MyConfig(PretrainedConfig):
    base_model_tp_plan = {
        "layers.*.self_attn.k_proj": "colwise",
        "layers.*.self_attn.v_proj": "colwise",
        "layers.*.self_attn.o_proj": "rowwise",
        "layers.*.mlp.gate_proj": "colwise",
        "layers.*.mlp.up_proj": "colwise",
        "layers.*.mlp.down_proj": "rowwise",
    }
    base_model_pp_plan = {
        "embed_tokens": (["input_ids"], ["inputs_embeds"]),
        "layers": (["hidden_states", "attention_mask"], ["hidden_states"]),
        "norm": (["hidden_states"], ["hidden_states"]),
    }
```

- `base_model_tp_plan` æ˜¯ä¸€ä¸ª `dict`ï¼Œå°†å®Œå…¨é™å®šçš„å±‚åç§°æ¨¡å¼æ˜ å°„åˆ°å¼ é‡å¹¶è¡Œæ ·å¼ï¼ˆç›®å‰ä»…æ”¯æŒ `"colwise"` å’Œ `"rowwise"`ï¼‰ã€‚
- `base_model_pp_plan` æ˜¯ä¸€ä¸ª `dict`ï¼Œå°†ç›´æ¥å­å±‚åç§°æ˜ å°„åˆ° `tuple` çš„ `list` çš„ `str`ï¼š
    * ä»…éœ€ä¸ºä¸åœ¨æ‰€æœ‰æµæ°´çº¿é˜¶æ®µçš„å±‚æ‰§è¡Œæ­¤æ“ä½œ
    * vLLM å‡è®¾åªæœ‰ä¸€ä¸ª `nn.ModuleList`ï¼Œå®ƒåˆ†å¸ƒåœ¨æµæ°´çº¿é˜¶æ®µä¸Š
    * `tuple` çš„ç¬¬ä¸€ä¸ªå…ƒç´ çš„ `list` åŒ…å«è¾“å…¥å‚æ•°çš„åç§°
    * `tuple` çš„æœ€åä¸€ä¸ªå…ƒç´ çš„ `list` åŒ…å«æ¨¡å‹ä»£ç ä¸­å±‚è¾“å‡ºçš„å˜é‡åç§°

## åŠ è½½æ¨¡å‹

### Hugging Face æ¨¡å‹ä¸­å¿ƒ

é»˜è®¤æƒ…å†µä¸‹ï¼ŒvLLM ä» [Hugging Face (HF) æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models) åŠ è½½æ¨¡å‹ã€‚è¦æ›´æ”¹æ¨¡å‹çš„ä¸‹è½½è·¯å¾„ï¼Œå¯ä»¥è®¾ç½® `HF_HOME` ç¯å¢ƒå˜é‡ï¼›æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhome)ã€‚

è¦ç¡®å®šç»™å®šçš„æ¨¡å‹æ˜¯å¦è¢«åŸç”Ÿæ”¯æŒï¼Œå¯ä»¥æ£€æŸ¥ HF ä»“åº“ä¸­çš„ `config.json` æ–‡ä»¶ã€‚
å¦‚æœ `"architectures"` å­—æ®µåŒ…å«ä»¥ä¸‹åˆ—å‡ºçš„æ¨¡å‹æ¶æ„ï¼Œåˆ™è¯¥æ¨¡å‹åº”è¢«åŸç”Ÿæ”¯æŒã€‚

æ¨¡å‹ä¸_éœ€è¦_è¢«åŸç”Ÿæ”¯æŒå³å¯åœ¨ vLLM ä¸­ä½¿ç”¨ã€‚
[Transformers åç«¯][transformers-backend] ä½¿ä½ èƒ½å¤Ÿç›´æ¥ä½¿ç”¨æ¨¡å‹çš„ Transformers å®ç°ï¼ˆç”šè‡³åŒ…æ‹¬ Hugging Face æ¨¡å‹ä¸­å¿ƒä¸Šçš„è¿œç¨‹ä»£ç ï¼ï¼‰ã€‚

!!! tip
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦çœŸæ­£å—æ”¯æŒçš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨è¿è¡Œæ—¶è¿è¡Œä»¥ä¸‹ç¨‹åºï¼š

    ```python
    from vllm import LLM

    # ä»…é€‚ç”¨äºç”Ÿæˆæ¨¡å‹ï¼ˆtask=generateï¼‰
    llm = LLM(model=..., task="generate")  # ä½ çš„æ¨¡å‹åç§°æˆ–è·¯å¾„
    output = llm.generate("ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯")
    print(output)

    # ä»…é€‚ç”¨äºæ± åŒ–æ¨¡å‹ï¼ˆtask={embed,classify,reward,score}ï¼‰
    llm = LLM(model=..., task="embed")  # ä½ çš„æ¨¡å‹åç§°æˆ–è·¯å¾„
    output = llm.encode("ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯")
    print(output)
    ```

    å¦‚æœ vLLM æˆåŠŸè¿”å›æ–‡æœ¬ï¼ˆå¯¹äºç”Ÿæˆæ¨¡å‹ï¼‰æˆ–éšè—çŠ¶æ€ï¼ˆå¯¹äºæ± åŒ–æ¨¡å‹ï¼‰ï¼Œåˆ™è¡¨æ˜ä½ çš„æ¨¡å‹å—æ”¯æŒã€‚

å¦åˆ™ï¼Œè¯·å‚é˜… [æ·»åŠ æ–°æ¨¡å‹][new-model] ä»¥è·å–åœ¨ vLLM ä¸­å®ç°æ¨¡å‹çš„è¯´æ˜ã€‚
æˆ–è€…ï¼Œä½ å¯ä»¥åœ¨ [GitHub ä¸Šæå‡ºé—®é¢˜](https://github.com/vllm-project/vllm/issues/new/choose) è¯·æ±‚ vLLM æ”¯æŒã€‚

#### ä¸‹è½½æ¨¡å‹

å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥ä½¿ç”¨ Hugging Face CLI æ¥ [ä¸‹è½½æ¨¡å‹](https://huggingface.co/docs/huggingface_hub/guides/cli#huggingface-cli-download) æˆ–æ¨¡å‹ä»“åº“ä¸­çš„ç‰¹å®šæ–‡ä»¶ï¼š

```console
# ä¸‹è½½æ¨¡å‹
huggingface-cli download HuggingFaceH4/zephyr-7b-beta

# æŒ‡å®šè‡ªå®šä¹‰ç¼“å­˜ç›®å½•
huggingface-cli download HuggingFaceH4/zephyr-7b-beta --cache-dir ./path/to/cache

# ä»æ¨¡å‹ä»“åº“ä¸‹è½½ç‰¹å®šæ–‡ä»¶
huggingface-cli download HuggingFaceH4/zephyr-7b-beta eval_results.json
```

#### åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹

ä½¿ç”¨ Hugging Face CLI æ¥ [ç®¡ç†æœ¬åœ°ç¼“å­˜ä¸­çš„æ¨¡å‹](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#scan-your-cache)ï¼š

```console
# åˆ—å‡ºç¼“å­˜çš„æ¨¡å‹
huggingface-cli scan-cache

# æ˜¾ç¤ºè¯¦ç»†ï¼ˆå†—é•¿ï¼‰è¾“å‡º
huggingface-cli scan-cache -v

# æŒ‡å®šè‡ªå®šä¹‰ç¼“å­˜ç›®å½•
huggingface-cli scan-cache --dir ~/.cache/huggingface/hub
```

#### åˆ é™¤ç¼“å­˜çš„æ¨¡å‹

ä½¿ç”¨ Hugging Face CLI äº¤äº’å¼åœ° [åˆ é™¤å·²ä¸‹è½½çš„æ¨¡å‹](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#clean-your-cache) ä»ç¼“å­˜ä¸­ï¼š

```console
# `delete-cache` å‘½ä»¤éœ€è¦é¢å¤–çš„ä¾èµ–é¡¹æ‰èƒ½ä½¿ç”¨ TUIã€‚
# è¯·è¿è¡Œ `pip install huggingface_hub[cli]` å®‰è£…å®ƒä»¬ã€‚

# å¯åŠ¨äº¤äº’å¼ TUI ä»¥é€‰æ‹©è¦åˆ é™¤çš„æ¨¡å‹
$ huggingface-cli delete-cache
? é€‰æ‹©è¦åˆ é™¤çš„ä¿®è®¢ç‰ˆæœ¬ï¼šå·²é€‰æ‹© 1 ä¸ªä¿®è®¢ç‰ˆæœ¬ï¼Œå ç”¨ 438.9Mã€‚
  â—‹ ä¸é€‰æ‹©ä»¥ä¸‹ä»»ä½•å†…å®¹ï¼ˆå¦‚æœé€‰æ‹©ï¼Œåˆ™ä¸ä¼šåˆ é™¤ä»»ä½•å†…å®¹ï¼‰ã€‚
æ¨¡å‹ BAAI/bge-base-en-v1.5ï¼ˆ438.9Mï¼Œä½¿ç”¨äº 1 å‘¨å‰ï¼‰
â¯ â—‰ a5beb1e3: main # 1 å‘¨å‰ä¿®æ”¹

æ¨¡å‹ BAAI/bge-large-en-v1.5ï¼ˆ1.3Gï¼Œä½¿ç”¨äº 1 å‘¨å‰ï¼‰
  â—‹ d4aa6901: main # 1 å‘¨å‰ä¿®æ”¹

æ¨¡å‹ BAAI/bge-reranker-baseï¼ˆ1.1Gï¼Œä½¿ç”¨äº 4 å‘¨å‰ï¼‰
  â—‹ 2cfc18c9: main # 4 å‘¨å‰ä¿®æ”¹

æŒ‰ <space> é€‰æ‹©ï¼ŒæŒ‰ <enter> ç¡®è®¤ï¼ŒæŒ‰ <ctrl+c> é€€å‡ºè€Œä¸è¿›è¡Œä¿®æ”¹ã€‚

# é€‰æ‹©åéœ€è¦ç¡®è®¤
? é€‰æ‹©è¦åˆ é™¤çš„ä¿®è®¢ç‰ˆæœ¬ï¼šå·²é€‰æ‹© 1 ä¸ªä¿®è®¢ç‰ˆæœ¬ã€‚
? å·²é€‰æ‹© 1 ä¸ªä¿®è®¢ç‰ˆæœ¬ï¼Œå ç”¨ 438.9Mã€‚ç¡®è®¤åˆ é™¤ï¼Ÿæ˜¯
å¼€å§‹åˆ é™¤ã€‚
å®Œæˆã€‚åˆ é™¤äº† 1 ä¸ªä»“åº“å’Œ 0 ä¸ªä¿®è®¢ç‰ˆæœ¬ï¼Œæ€»è®¡ 438.9Mã€‚
```

#### ä½¿ç”¨ä»£ç†

ä»¥ä¸‹æ˜¯ä» Hugging Face åŠ è½½/ä¸‹è½½æ¨¡å‹æ—¶ä½¿ç”¨ä»£ç†çš„ä¸€äº›æç¤ºï¼š

- ä¸ºä½ çš„ä¼šè¯å…¨å±€è®¾ç½®ä»£ç†ï¼ˆæˆ–åœ¨ profile æ–‡ä»¶ä¸­è®¾ç½®ï¼‰ï¼š

```shell
export http_proxy=http://your.proxy.server:port
export https_proxy=http://your.proxy.server:port
```

- ä»…ä¸ºå½“å‰å‘½ä»¤è®¾ç½®ä»£ç†ï¼š

```shell
https_proxy=http://your.proxy.server:port huggingface-cli download <model_name>

# æˆ–ç›´æ¥ä½¿ç”¨ vllm å‘½ä»¤
https_proxy=http://your.proxy.server:port vllm serve <model_name> --disable-log-requests
```

- åœ¨ Python è§£é‡Šå™¨ä¸­è®¾ç½®ä»£ç†ï¼š

```python
import os

os.environ['http_proxy'] = 'http://your.proxy.server:port'
os.environ['https_proxy'] = 'http://your.proxy.server:port'
```

### ModelScope

è¦ä½¿ç”¨ [ModelScope](https://www.modelscope.cn) çš„æ¨¡å‹è€Œä¸æ˜¯ Hugging Face æ¨¡å‹ä¸­å¿ƒï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```shell
export VLLM_USE_MODELSCOPE=True
```

å¹¶ä½¿ç”¨ `trust_remote_code=True`ã€‚

```python
from vllm import LLM

llm = LLM(model=..., revision=..., task=..., trust_remote_code=True)

# ä»…é€‚ç”¨äºç”Ÿæˆæ¨¡å‹ï¼ˆtask=generateï¼‰
output = llm.generate("ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯")
print(output)

# ä»…é€‚ç”¨äºæ± åŒ–æ¨¡å‹ï¼ˆtask={embed,classify,reward,score}ï¼‰
output = llm.encode("ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯")
print(output)
```

[](){ #feature-status-legend }

## åŠŸèƒ½çŠ¶æ€å›¾ä¾‹

- âœ…ï¸ è¡¨ç¤ºè¯¥æ¨¡å‹æ”¯æŒè¯¥åŠŸèƒ½ã€‚

- ğŸš§ è¡¨ç¤ºè¯¥åŠŸèƒ½å·²è®¡åˆ’ä½†å°šæœªæ”¯æŒã€‚

- âš ï¸ è¡¨ç¤ºè¯¥åŠŸèƒ½å¯ç”¨ï¼Œä½†å¯èƒ½å­˜åœ¨å·²çŸ¥é—®é¢˜æˆ–é™åˆ¶ã€‚

[](){ #supported-text-models }

## çº¯æ–‡æœ¬è¯­è¨€æ¨¡å‹åˆ—è¡¨

### ç”Ÿæˆæ¨¡å‹

æœ‰å…³å¦‚ä½•ä½¿ç”¨ç”Ÿæˆæ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [æ­¤é¡µé¢][generative-models]ã€‚

#### æ–‡æœ¬ç”Ÿæˆ

ä½¿ç”¨ `--task generate` æŒ‡å®šã€‚

| æ¶æ„                                              | æ¨¡å‹                                                | ç¤ºä¾‹ HF æ¨¡å‹                                                                                                                                                                | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|---------------------------------------------------|-----------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------|
| `AquilaForCausalLM`                               | Aquila, Aquila2                                     | `BAAI/Aquila-7B`, `BAAI/AquilaChat-7B` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `ArcticForCausalLM`                               | Arctic                                              | `Snowflake/snowflake-arctic-base`, `Snowflake/snowflake-arctic-instruct` ç­‰                                                                                                  |                        | âœ…ï¸                          |
| `BaiChuanForCausalLM`                             | Baichuan2, Baichuan                                 | `baichuan-inc/Baichuan2-13B-Chat`, `baichuan-inc/Baichuan-7B` ç­‰                                                                                                             | âœ…ï¸                     | âœ…ï¸                          |
| `BambaForCausalLM`                                | Bamba                                               | `ibm-ai-platform/Bamba-9B-fp8`, `ibm-ai-platform/Bamba-9B`                                                                                                                   | âœ…ï¸                     | âœ…ï¸                          |
| `BloomForCausalLM`                                | BLOOM, BLOOMZ, BLOOMChat                            | `bigscience/bloom`, `bigscience/bloomz` ç­‰                                                                                                                                   |                        | âœ…ï¸                          |
| `BartForConditionalGeneration`                    | BART                                                | `facebook/bart-base`, `facebook/bart-large-cnn` ç­‰                                                                                                                           |                        |                             |
| `ChatGLMModel`, `ChatGLMForConditionalGeneration` | ChatGLM                                             | `THUDM/chatglm2-6b`, `THUDM/chatglm3-6b`, `ShieldLM-6B-chatglm3` ç­‰                                                                                                          | âœ…ï¸                     | âœ…ï¸                          |
| `CohereForCausalLM`, `Cohere2ForCausalLM`         | Command-R                                           | `CohereForAI/c4ai-command-r-v01`, `CohereForAI/c4ai-command-r7b-12-2024` ç­‰                                                                                                  | âœ…ï¸                     | âœ…ï¸                          |
| `DbrxForCausalLM`                                 | DBRX                                                | `databricks/dbrx-base`, `databricks/dbrx-instruct` ç­‰                                                                                                                        |                        | âœ…ï¸                          |
| `DeciLMForCausalLM`                               | DeciLM                                              | `nvidia/Llama-3_3-Nemotron-Super-49B-v1` ç­‰                                                                                                                                  | âœ…ï¸                     | âœ…ï¸                          |
| `DeepseekForCausalLM`                             | DeepSeek                                            | `deepseek-ai/deepseek-llm-67b-base`, `deepseek-ai/deepseek-llm-7b-chat` ç­‰                                                                                                   |                        | âœ…ï¸                          |
| `DeepseekV2ForCausalLM`                           | DeepSeek-V2                                         | `deepseek-ai/DeepSeek-V2`, `deepseek-ai/DeepSeek-V2-Chat` ç­‰                                                                                                                 |                        | âœ…ï¸                          |
| `DeepseekV3ForCausalLM`                           | DeepSeek-V3                                         | `deepseek-ai/DeepSeek-V3-Base`, `deepseek-ai/DeepSeek-V3` ç­‰                                                                                                                 |                        | âœ…ï¸                          |
| `ExaoneForCausalLM`                               | EXAONE-3                                            | `LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `FalconForCausalLM`                               | Falcon                                              | `tiiuae/falcon-7b`, `tiiuae/falcon-40b`, `tiiuae/falcon-rw-7b` ç­‰                                                                                                            |                        | âœ…ï¸                          |
| `FalconMambaForCausalLM`                          | FalconMamba                                         | `tiiuae/falcon-mamba-7b`, `tiiuae/falcon-mamba-7b-instruct` ç­‰                                                                                                               |                        | âœ…ï¸                          |
| `FalconH1ForCausalLM`                             | Falcon-H1                                           | `tiiuae/Falcon-H1-34B-Base`, `tiiuae/Falcon-H1-34B-Instruct` ç­‰                                                                                                              | âœ…ï¸                     | âœ…ï¸                          |
| `GemmaForCausalLM`                                | Gemma                                               | `google/gemma-2b`, `google/gemma-1.1-2b-it` ç­‰                                                                                                                               | âœ…ï¸                     | âœ…ï¸                          |
| `Gemma2ForCausalLM`                               | Gemma 2                                             | `google/gemma-2-9b`, `google/gemma-2-27b` ç­‰                                                                                                                                 | âœ…ï¸                     | âœ…ï¸                          |
| `Gemma3ForCausalLM`                               | Gemma 3                                             | `google/gemma-3-1b-it` ç­‰                                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `GlmForCausalLM`                                  | GLM-4                                               | `THUDM/glm-4-9b-chat-hf` ç­‰                                                                                                                                                  | âœ…ï¸                     | âœ…ï¸                          |
| `Glm4ForCausalLM`                                 | GLM-4-0414                                          | `THUDM/GLM-4-32B-0414` ç­‰                                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `GPT2LMHeadModel`                                 | GPT-2                                               | `gpt2`, `gpt2-xl` ç­‰                                                                                                                                                         |                        | âœ…ï¸                          |
| `GPTBigCodeForCausalLM`                           | StarCoder, SantaCoder, WizardCoder                  | `bigcode/starcoder`, `bigcode/gpt_bigcode-santacoder`, `WizardLM/WizardCoder-15B-V1.0` ç­‰                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `GPTJForCausalLM`                                 | GPT-J                                               | `EleutherAI/gpt-j-6b`, `nomic-ai/gpt4all-j` ç­‰                                                                                                                               |                        | âœ…ï¸                          |
| `GPTNeoXForCausalLM`                              | GPT-NeoX, Pythia, OpenAssistant, Dolly V2, StableLM | `EleutherAI/gpt-neox-20b`, `EleutherAI/pythia-12b`, `OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5`, `databricks/dolly-v2-12b`, `stabilityai/stablelm-tuned-alpha-7b` ç­‰   |                        | âœ…ï¸                          |
| `GraniteForCausalLM`                              | Granite 3.0, Granite 3.1, PowerLM                   | `ibm-granite/granite-3.0-2b-base`, `ibm-granite/granite-3.1-8b-instruct`, `ibm/PowerLM-3b` ç­‰                                                                               | âœ…ï¸                     | âœ…ï¸                          |
| `GraniteMoeForCausalLM`                           | Granite 3.0 MoE, PowerMoE                           | `ibm-granite/granite-3.0-1b-a400m-base`, `ibm-granite/granite-3.0-3b-a800m-instruct`, `ibm/PowerMoE-3b` ç­‰                                                                 | âœ…ï¸                     | âœ…ï¸                          |
| `GraniteMoeHybridForCausalLM`                     | Granite 4.0 MoE Hybrid                              | `ibm-granite/granite-4.0-tiny-preview` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `GraniteMoeSharedForCausalLM`                     | Granite MoE Shared                                  | `ibm-research/moe-7b-1b-active-shared-experts`ï¼ˆæµ‹è¯•æ¨¡å‹ï¼‰                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `GritLM`                                          | GritLM                                              | `parasail-ai/GritLM-7B-vllm`                                                                                                                                                 | âœ…ï¸                     | âœ…ï¸                          |
| `Grok1ModelForCausalLM`                           | Grok1                                               | `hpcai-tech/grok-1`                                                                                                                                                          | âœ…ï¸                     | âœ…ï¸                          |
| `InternLMForCausalLM`                             | InternLM                                            | `internlm/internlm-7b`, `internlm/internlm-chat-7b` ç­‰                                                                                                                       | âœ…ï¸                     | âœ…ï¸                          |
| `InternLM2ForCausalLM`                            | InternLM2                                           | `internlm/internlm2-7b`, `internlm/internlm2-chat-7b` ç­‰                                                                                                                     | âœ…ï¸                     | âœ…ï¸                          |
| `InternLM3ForCausalLM`                            | InternLM3                                           | `internlm/internlm3-8b-instruct` ç­‰                                                                                                                                          | âœ…ï¸                     | âœ…ï¸                          |
| `JAISLMHeadModel`                                 | Jais                                                | `inceptionai/jais-13b`, `inceptionai/jais-13b-chat`, `inceptionai/jais-30b-v3`, `inceptionai/jais-30b-chat-v3` ç­‰                                                           |                        | âœ…ï¸                          |
| `JambaForCausalLM`                                | Jamba                                               | `ai21labs/AI21-Jamba-1.5-Large`, `ai21labs/AI21-Jamba-1.5-Mini`, `ai21labs/Jamba-v0.1` ç­‰                                                                                   | âœ…ï¸                     | âœ…ï¸                          |
| `LlamaForCausalLM`                                | Llama 3.1, Llama 3, Llama 2, LLaMA, Yi              | `meta-llama/Meta-Llama-3.1-405B-Instruct`, `meta-llama/Meta-Llama-3.1-70B`, `meta-llama/Meta-Llama-3-70B-Instruct`, `meta-llama/Llama-2-70b-hf`, `01-ai/Yi-34B` ç­‰         | âœ…ï¸                     | âœ…ï¸                          |
| `MambaForCausalLM`                                | Mamba                                               | `state-spaces/mamba-130m-hf`, `state-spaces/mamba-790m-hf`, `state-spaces/mamba-2.8b-hf` ç­‰                                                                                  |                        | âœ…ï¸                          |
| `MiniCPMForCausalLM`                              | MiniCPM                                             | `openbmb/MiniCPM-2B-sft-bf16`, `openbmb/MiniCPM-2B-dpo-bf16`, `openbmb/MiniCPM-S-1B-sft` ç­‰                                                                                 | âœ…ï¸                     | âœ…ï¸                          |
| `MiniCPM3ForCausalLM`                             | MiniCPM3                                            | `openbmb/MiniCPM3-4B` ç­‰                                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `MistralForCausalLM`                              | Mistral, Mistral-Instruct                           | `mistralai/Mistral-7B-v0.1`, `mistralai/Mistral-7B-Instruct-v0.1` ç­‰                                                                                                        | âœ…ï¸                     | âœ…ï¸                          |
| `MixtralForCausalLM`                              | Mixtral-8x7B, Mixtral-8x7B-Instruct                 | `mistralai/Mixtral-8x7B-v0.1`, `mistralai/Mixtral-8x7B-Instruct-v0.1`, `mistral-community/Mixtral-8x22B-v0.1` ç­‰                                                              | âœ…ï¸                     | âœ…ï¸                          |
| `MPTForCausalLM`                                  | MPT, MPT-Instruct, MPT-Chat, MPT-StoryWriter                                 | `mosaicml/mpt-7b`, `mosaicml/mpt-7b-storywriter`, `mosaicml/mpt-30b` ç­‰                                                                                                     |                        | âœ…ï¸                          |
| `NemotronForCausalLM`                             | Nemotron-3, Nemotron-4, Minitron                    | `nvidia/Minitron-8B-Base`, `mgoin/Nemotron-4-340B-Base-hf-FP8` ç­‰                                                                                                            | âœ…ï¸                     | âœ…ï¸                          |
| `NemotronHForCausalLM`                            | Nemotron-H                                          | `nvidia/Nemotron-H-8B-Base-8K`, `nvidia/Nemotron-H-47B-Base-8K`, `nvidia/Nemotron-H-56B-Base-8K` ç­‰                                                                         | âœ…ï¸                     | âœ…ï¸                          |
| `OLMoForCausalLM`                                 | OLMo                                                | `allenai/OLMo-1B-hf`, `allenai/OLMo-7B-hf` ç­‰                                                                                                                                |                        | âœ…ï¸                          |
| `OLMo2ForCausalLM`                                | OLMo2                                               | `allenai/OLMo-2-0425-1B` ç­‰                                                                 |                        | âœ…ï¸                          |
| `OLMoEForCausalLM`                                | OLMoE                                               | `allenai/OLMoE-1B-7B-0924`, `allenai/OLMoE-1B-7B-0924-Instruct` ç­‰                                                                                                           |                        | âœ…ï¸                          |
| `OPTForCausalLM`                                  | OPT, OPT-IML                                        | `facebook/opt-66b`, `facebook/opt-iml-max-30b` ç­‰                                                                                                                           |                        | âœ…ï¸                          |
| `OrionForCausalLM`                                | Orion                                               | `OrionStarAI/Orion-14B-Base`, `OrionStarAI/Orion-14B-Chat` ç­‰                                                                                                                |                        | âœ…ï¸                                                                                  |
| `PhiForCausalLM`                                 | Phi                                                 | `microsoft/phi-1_5`, `microsoft/phi-2` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                                                                                  |
| `Phi3ForCausalLM`                                 | Phi-4, Phi-3                                        | `microsoft/Phi-4-mini-instruct`, `microsoft/Phi-4`, `microsoft/Phi-3-mini-4k-instruct`, `microsoft/Phi-3-mini-128k-instruct`, `microsoft/Phi-3-medium-128k-instruct` ç­‰   | âœ…ï¸                     | âœ…ï¸                                                                 |
| `Phi3SmallForCausalLM`                            | Phi-3-Small                                         | `microsoft/Phi-3-small-8k-instruct`, `microsoft/Phi-3-small-128k-instruct` ç­‰                                                                                                |                        | âœ…                                                                               |
| `PhiMoEForCausalLM`                               | Phi-3.5-MoE                                         | `microsoft/Phi-3.5-MoE-instruct` ç­‰                                                                                                                                        | âœ…ï¸                                                                                     | âœ…ï¸                                                                 |
| `PersimmonForCausalLM`                            | Persimmon                                           | `adept/persimmon-8b-base`, `adept/persimmon-8b-chat` ç­‰                                                                                                                      |                        | âœ…                                                                               |
| `Plamo2ForCausalLM`                               | PLaMo2                                               | `pfnet/plamo-2-1b`, `pfnet/plamo-2-8b` ç­‰                                                                                                                                       |                        |                                                                                             |
| `QWenLMHeadModel`                                 | Qwen                                                | `Qwen/Qwen-7B`, `Qwen/Qwen-7B-Chat` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `Qwen2ForCausalLM`                                | QwQ, Qwen2                                          | `Qwen/QwQ-32B-Preview`, `Qwen/Qwen2-7B-Instruct`, `Qwen/Qwen2-7B` ç­‰                                                                                                       | âœ…ï¸                     | âœ…ï¸                          |
| `Qwen2MoeForCausalLM`                             | Qwen2MoE                                            | `Qwen/Qwen1.5-MoE-A2.7B`, `Qwen/Qwen1.5-MoE-A2.7B-Chat` ç­‰                                                                                                                 |                        | âœ…ï¸                          |
| `Qwen3ForCausalLM`                                | Qwen3                                               | `Qwen/Qwen3-8B` ç­‰                                                                                                                                                         | âœ…ï¸                     | âœ…ï¸                          |
| `Qwen3MoeForCausalLM`                             | Qwen3MoE                                            | `Qwen/Qwen3-30B-A3B` ç­‰                                                                                                                                                    |                        | âœ…ï¸                          |
| `StableLmForCausalLM`                             | StableLM                                            | `stabilityai/stablelm-3b-4e1t`, `stabilityai/stablelm-base-alpha-7b-v2` ç­‰                                                                                                 |                        |                             |
| `Starcoder2ForCausalLM`                           | Starcoder2                                          | `bigcode/starcoder2-3b`, `bigcode/starcoder2-7b`, `bigcode/starcoder2-15b` ç­‰                                                                                              |                        | âœ…ï¸                          |
| `SolarForCausalLM`                                | Solar Pro                                           | `upstage/solar-pro-preview-instruct` ç­‰                                                                                                                                    | âœ…ï¸                     | âœ…ï¸                          |
| `TeleChat2ForCausalLM`                            | TeleChat2                                           | `Tele-AI/TeleChat2-3B`, `Tele-AI/TeleChat2-7B`, `Tele-AI/TeleChat2-35B` ç­‰                                                                                                 | âœ…ï¸                     | âœ…ï¸                          |
| `TeleFLMForCausalLM`                              | TeleFLM                                             | `CofeAI/FLM-2-52B-Instruct-2407`, `CofeAI/Tele-FLM` ç­‰                                                                                                                     | âœ…ï¸                     | âœ…ï¸                          |
| `XverseForCausalLM`                               | XVERSE                                              | `xverse/XVERSE-7B-Chat`, `xverse/XVERSE-13B-Chat`, `xverse/XVERSE-65B-Chat` ç­‰                                                                                             | âœ…ï¸                     | âœ…ï¸                          |
| `MiniMaxText01ForCausalLM`                        | MiniMax-Text                                        | `MiniMaxAI/MiniMax-Text-01` ç­‰                                                                                                                                            |                        |                             |
| `Zamba2ForCausalLM`                               | Zamba2                                              | `Zyphra/Zamba2-7B-instruct`, `Zyphra/Zamba2-2.7B-instruct`, `Zyphra/Zamba2-1.2B-instruct` ç­‰                                                                               |                        |                             |

!!! note
    å½“å‰ï¼ŒvLLM çš„ ROCm ç‰ˆæœ¬ä»…æ”¯æŒ Mistral å’Œ Mixtralï¼Œä¸Šä¸‹æ–‡é•¿åº¦æœ€å¤šä¸º 4096ã€‚

### æ± åŒ–æ¨¡å‹

æœ‰å…³å¦‚ä½•ä½¿ç”¨æ± åŒ–æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [æ­¤é¡µé¢](./pooling_models.md)ã€‚

!!! warning
    ç”±äºä¸€äº›æ¨¡å‹æ¶æ„åŒæ—¶æ”¯æŒç”Ÿæˆå’Œæ± åŒ–ä»»åŠ¡ï¼Œ
    ä½ åº”æ˜ç¡®æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œä»¥ç¡®ä¿æ¨¡å‹ä»¥æ± åŒ–æ¨¡å¼è€Œä¸æ˜¯ç”Ÿæˆæ¨¡å¼ä½¿ç”¨ã€‚

#### æ–‡æœ¬åµŒå…¥

ä½¿ç”¨ `--task embed` æŒ‡å®šã€‚

| æ¶æ„                                           | æ¨¡å‹                | ç¤ºä¾‹ HF æ¨¡å‹                                                                                                   | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|--------------------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------|
| `BertModel`                                            | åŸºäº BERT           | `BAAI/bge-base-en-v1.5`, `Snowflake/snowflake-arctic-embed-xs` ç­‰                                                   |                        |                             |
| `Gemma2Model`                                          | åŸºäº Gemma 2        | `BAAI/bge-multilingual-gemma2` ç­‰                                                                                   | âœ…ï¸                     |                             |
| `GritLM`                                               | GritLM              | `parasail-ai/GritLM-7B-vllm`                                                                                        | âœ…ï¸                     | âœ…ï¸                          |
| `GteModel`                                             | Arctic-Embed-2.0-M  | `Snowflake/snowflake-arctic-embed-m-v2.0`                                                                           | ï¸                      |                             |
| `GteNewModel`                                          | mGTE-TRMï¼ˆè§æ³¨é‡Šï¼‰  | `Alibaba-NLP/gte-multilingual-base` ç­‰                                                                              | ï¸                      | ï¸                           |
| `ModernBertModel`                                      | åŸºäº ModernBERT     | `Alibaba-NLP/gte-modernbert-base` ç­‰                                                                                | ï¸                      | ï¸                           |
| `NomicBertModel`                                       | Nomic BERT          | `nomic-ai/nomic-embed-text-v1`, `nomic-ai/nomic-embed-text-v2-moe`, `Snowflake/snowflake-arctic-embed-m-long` ç­‰  | ï¸                      | ï¸                           |
| `LlamaModel`, `LlamaForCausalLM`, `MistralModel` ç­‰    | åŸºäº Llama          | `intfloat/e5-mistral-7b-instruct` ç­‰                                                                                | âœ…ï¸                     | âœ…ï¸                          |
| `Qwen2Model`, `Qwen2ForCausalLM`                       | åŸºäº Qwen2          | `ssmits/Qwen2-7B-Instruct-embed-base`ï¼ˆè§æ³¨é‡Šï¼‰ï¼Œ`Alibaba-NLP/gte-Qwen2-7B-instruct`ï¼ˆè§æ³¨é‡Šï¼‰ç­‰                   | âœ…ï¸                     | âœ…ï¸                          |
| `RobertaModel`, `RobertaForMaskedLM`                   | åŸºäº RoBERTa        | `sentence-transformers/all-roberta-large-v1` ç­‰                                                                     |                        |                             |

!!! note
    `ssmits/Qwen2-7B-Instruct-embed-base` çš„ Sentence Transformers é…ç½®å®šä¹‰ä¸æ­£ç¡®ã€‚
    ä½ éœ€è¦é€šè¿‡ä¼ é€’ `--override-pooler-config '{"pooling_type": "MEAN"}'` æ‰‹åŠ¨è®¾ç½®å‡å€¼æ± åŒ–ã€‚

!!! note
    å¯¹äº `Alibaba-NLP/gte-Qwen2-*`ï¼Œä½ éœ€è¦å¯ç”¨ `--trust-remote-code` ä»¥åŠ è½½æ­£ç¡®çš„åˆ†è¯å™¨ã€‚
    å‚è§ [HF Transformers ä¸Šçš„ç›¸å…³é—®é¢˜](https://github.com/huggingface/transformers/issues/34882)ã€‚

!!! note
    `jinaai/jina-embeddings-v3` é€šè¿‡ LoRA æ”¯æŒå¤šç§ä»»åŠ¡ï¼Œè€Œ vLLM ç›®å‰ä»…é€šè¿‡åˆå¹¶ LoRA æƒé‡ä¸´æ—¶æ”¯æŒæ–‡æœ¬åŒ¹é…ä»»åŠ¡ã€‚

!!! note
    ç¬¬äºŒä»£ GTE æ¨¡å‹ mGTE-TRMï¼‰è¢«å‘½åä¸º `NewModel`ã€‚åç§° `NewModel` è¿‡äºé€šç”¨ï¼Œä½ åº”è®¾ç½® `--hf-overrides '{"architecture": ["GteNewModel"]}'` ä»¥æŒ‡å®šä½¿ç”¨ `GteNewModel` æ¶æ„ã€‚

å¦‚æœä½ çš„æ¨¡å‹ä¸åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬å°†å°è¯•ä½¿ç”¨ [as_embedding_model][vllm.model_executor.models.adapters.as_embedding_model] è‡ªåŠ¨è½¬æ¢æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä»æœ€åä¸€ä¸ªæ ‡è®°çš„å½’ä¸€åŒ–éšè—çŠ¶æ€ä¸­æå–æ•´ä¸ªæç¤ºçš„åµŒå…¥ã€‚

#### å¥–åŠ±å»ºæ¨¡

ä½¿ç”¨ `--task reward` æŒ‡å®šã€‚

| æ¶æ„                      | æ¨¡å‹                  | ç¤ºä¾‹ HF æ¨¡å‹                                                               | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|---------------------------|-----------------------|------------------------------------------------------------------------|------------------------|-----------------------------|
| `InternLM2ForRewardModel`   | åŸºäº InternLM2         | `internlm/internlm2-1_8b-reward`, `internlm/internlm2-7b-reward` ç­‰   | âœ…ï¸                     | âœ…ï¸                          |
| `LlamaForCausalLM`         | åŸºäº Llama            | `peiyi9979/math-shepherd-mistral-7b-prm` ç­‰                       | âœ…ï¸                     | âœ…ï¸                          |
| `Qwen2ForRewardModel`      | åŸºäº Qwen2            | `Qwen/Qwen2.5-Math-RM-72B` ç­‰                                       | âœ…ï¸                     | âœ…ï¸                          |

å¦‚æœä½ çš„æ¨¡å‹ä¸åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬å°†å°è¯•ä½¿ç”¨ [as_reward_model][vllm.model_executor.models.adapters.as_reward_model] è‡ªåŠ¨è½¬æ¢æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›æ¯ä¸ªæ ‡è®°çš„éšè—çŠ¶æ€ã€‚

!!! warning
    å¯¹äºåƒ `peiyi9979/math-shepherd-mistral-7b-prm` è¿™æ ·çš„è¿‡ç¨‹ç›‘ç£å¥–åŠ±æ¨¡å‹ï¼Œåº”æ˜ç¡®è®¾ç½®æ± åŒ–é…ç½®ï¼Œ
    ä¾‹å¦‚ï¼š`--override-pooler-config '{"pooling_type": "STEP", "step_tag_id": 123, "returned_token_ids": [456, 789]}'`ã€‚

#### åˆ†ç±»

ä½¿ç”¨ `--task classify` æŒ‡å®šã€‚

| æ¶æ„                              | æ¨¡å‹       | ç¤ºä¾‹ HF æ¨¡å‹                             | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|-----------------------------------|------------|------------------------------------------|------------------------|-----------------------------|
| `JambaForSequenceClassification`  | Jamba      | `ai21labs/Jamba-tiny-reward-dev` ç­‰      | âœ…ï¸                     | âœ…ï¸                          |

å¦‚æœä½ çš„æ¨¡å‹ä¸åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬å°†å°è¯•ä½¿ç”¨ [as_classification_model][vllm.model_executor.models.adapters.as_classification_model] è‡ªåŠ¨è½¬æ¢æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä»æœ€åä¸€ä¸ªæ ‡è®°çš„ softmax éšè—çŠ¶æ€ä¸­æå–ç±»æ¦‚ç‡ã€‚

#### å¥å­å¯¹è¯„åˆ†

ä½¿ç”¨ `--task score` æŒ‡å®šã€‚

| æ¶æ„                                  | æ¨¡å‹                | ç¤ºä¾‹ HF æ¨¡å‹                                |
|---------------------------------------|---------------------|----------------------------------------------|
| `BertForSequenceClassification`       | åŸºäº BERT           | `cross-encoder/ms-marco-MiniLM-L-6-v2` ç­‰   |
| `RobertaForSequenceClassification`    | åŸºäº RoBERTa        | `cross-encoder/quora-roberta-base` ç­‰       |
| `XLMRobertaForSequenceClassification` | åŸºäº XLM-RoBERTa    | `BAAI/bge-reranker-v2-m3` ç­‰                |

[](){ #supported-mm-models }

## å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åˆ—è¡¨

ä»¥ä¸‹æ¨¡æ€æ ¹æ®æ¨¡å‹æ”¯æŒï¼š

- **T** æ–‡æœ¬
- **I** å›¾åƒ
- **V** è§†é¢‘
- **A** éŸ³é¢‘

ä»»ä½•é€šè¿‡ `+` è¿æ¥çš„æ¨¡æ€ç»„åˆéƒ½å—æ”¯æŒã€‚

- ä¾‹å¦‚ï¼š`T + I` è¡¨ç¤ºæ¨¡å‹æ”¯æŒçº¯æ–‡æœ¬ã€çº¯å›¾åƒä»¥åŠæ–‡æœ¬ä¸å›¾åƒçš„è¾“å…¥ã€‚

å¦ä¸€æ–¹é¢ï¼Œç”¨ `/` åˆ†éš”çš„æ¨¡æ€æ˜¯äº’æ–¥çš„ã€‚

- ä¾‹å¦‚ï¼š`T / I` è¡¨ç¤ºæ¨¡å‹æ”¯æŒçº¯æ–‡æœ¬å’Œçº¯å›¾åƒè¾“å…¥ï¼Œä½†ä¸æ”¯æŒæ–‡æœ¬ä¸å›¾åƒçš„è¾“å…¥ã€‚

æœ‰å…³å¦‚ä½•å‘æ¨¡å‹ä¼ é€’å¤šæ¨¡æ€è¾“å…¥çš„ä¿¡æ¯ï¼Œè¯·å‚è§ [æ­¤é¡µé¢][multimodal-inputs]ã€‚

!!! warning
    **è¦åœ¨ vLLM V0 ä¸­å¯ç”¨æ¯ä¸ªæ–‡æœ¬æç¤ºçš„å¤šä¸ªå¤šæ¨¡æ€è¾“å…¥ï¼Œä½ éœ€è¦è®¾ç½®** `limit_mm_per_prompt`ï¼ˆç¦»çº¿æ¨ç†ï¼‰
    æˆ– `--mlimit-mm-per-prompt`ï¼ˆåœ¨çº¿æœåŠ¡ï¼‰ã€‚ä¾‹å¦‚ï¼Œè¦å¯ç”¨æ¯ä¸ªæ–‡æœ¬æç¤ºæœ€å¤šä¼ é€’ 4 å¼ å›¾åƒï¼š

    ç¦»çº¿æ¨ç†ï¼š

    ```python
    from vllm import LLM

    llm = LLM(
        model="Qwen/Qwen2-VL-7B-Instruct",
        limit_mm_per_prompt={"image": 4},
    )
    ```

    åœ¨çº¿æœåŠ¡ï¼š

    ```bash
    vllm serve Qwen/Qwen2-VL-7B-Instruct --limit-mm-per-prompt '{"image":4}'
    ```

    **å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ vLLM V1ï¼Œåˆ™ä¸å†éœ€è¦æ­¤è®¾ç½®ã€‚**

!!! note
    vLLM å½“å‰ä»…æ”¯æŒå¯¹å¤šæ¨¡æ€æ¨¡å‹çš„è¯­è¨€éª¨å¹²æ·»åŠ  LoRAã€‚

### ç”Ÿæˆæ¨¡å‹

æœ‰å…³å¦‚ä½•ä½¿ç”¨ç”Ÿæˆæ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [æ­¤é¡µé¢][generative-models]ã€‚

#### æ–‡æœ¬ç”Ÿæˆ

ä½¿ç”¨ `--task generate` æŒ‡å®šã€‚

| æ¶æ„                                          | æ¨¡å‹                                                                     | è¾“å…¥                                                                | ç¤ºä¾‹ HF æ¨¡å‹                                                                                                   | [LoRA][lora-adapter]   | [PP][distributed-serving] | [V1](gh-issue:8779)   |
|-----------------------------------------------|--------------------------------------------------------------------------|---------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|------------------------|---------------------------|-----------------------|
| `AriaForConditionalGeneration`                | Aria                                                                     | T + I<sup>+</sup>                                                   | `rhymes-ai/Aria`                                                                                               |                        |                           | âœ…           |
| `AyaVisionForConditionalGeneration`           | Aya Vision                                                               | T + I<sup>+</sup>                                                   | `CohereForAI/aya-vision-8b`, `CohereForAI/aya-vision-32b` ç­‰                                                    |                        | âœ…                          | âœ…           |
| `Blip2ForConditionalGeneration`               | BLIP-2                                                                   | T + I<sup>E</sup>                                                   | `Salesforce/blip2-opt-2.7b`, `Salesforce/blip2-opt-6.7b` ç­‰                                                   |                        | âœ…                          | âœ…          |
| `ChameleonForConditionalGeneration`           | Chameleon                                                                | T + I                                                               | `facebook/chameleon-7b` ç­‰                                                                                     |                        | âœ…                          | âœ…           |
| `DeepseekVLV2ForCausalLM`<sup>^</sup>         | DeepSeek-VL2                                                             | T + I<sup>+</sup>                                                   | `deepseek-ai/deepseek-vl2-tiny`, `deepseek-ai/deepseek-vl2-small`, `deepseek-ai/deepseek-vl2` ç­‰             |                        | âœ…                           | âœ…           |
| `Florence2ForConditionalGeneration`           | Florence-2                                                                | T + I                                                               | `microsoft/Florence-2-base`, `microsoft/Florence-2-large` ç­‰                                    |                        |                             |                       |
| `FuyuForCausalLM`                             | Fuyu                                                                     | T + I                                                               | `adept/fuyu-8b` ç­‰                                                                                             |                        | âœ…                           | âœ…          |
| `Gemma3ForConditionalGeneration`              | Gemma 3                                                                  | T + I<sup>+</sup>                                                   | `google/gemma-3-4b-it`, `google/gemma-3-27b-it` ç­‰                                                             | âœ…                      | âœ…                          | âš ï¸          |
| `GLM4VForCausalLM`<sup>^</sup>                | GLM-4V                                                                   | T + I                                                               | `THUDM/glm-4v-9b`, `THUDM/cogagent-9b-20241220` ç­‰                                                             | âœ…                      | âœ…                          | âœ…           |
| `GraniteSpeechForConditionalGeneration`       | Granite Speech                                                           | T + A                                                               | `ibm-granite/granite-speech-3.3-8b`                                                                            | âœ…                      | âœ…                          | âœ…           |
| `H2OVLChatModel`                              | H2OVL                                                                    | T + I<sup>E+</sup>                                                  | `h2oai/h2ovl-mississippi-800m`, `h2oai/h2ovl-mississippi-2b` ç­‰                                               |                        | âœ…                          | âœ…\*         |
| `Idefics3ForConditionalGeneration`            | Idefics3                                                                 | T + I                                                               | `HuggingFaceM4/Idefics3-8B-Llama3` ç­‰                                                                          | âœ…                      |                           | âœ…           |
| `InternVLChatModel`                           | InternVL 3.0, InternVideo 2.5, InternVL 2.5, Mono-InternVL, InternVL 2.0 | T + I<sup>E+</sup> + (V<sup>E+</sup>)                               | `OpenGVLab/InternVL3-9B`, `OpenGVLab/InternVideo2_5_Chat_8B`, `OpenGVLab/InternVL2_5-4B`, `OpenGVLab/Mono-InternVL-2B`, `OpenGVLab/InternVL2-4B` ç­‰ | âœ…                      | âœ…                          | âœ…           |
| `KimiVLForConditionalGeneration`              | Kimi-VL-A3B-Instruct, Kimi-VL-A3B-Thinking                               | T + I<sup>+</sup>                                                   | `moonshotai/Kimi-VL-A3B-Instruct`, `moonshotai/Kimi-VL-A3B-Thinking`                                           |                        |                           | âœ…           |
| `Llama4ForConditionalGeneration`              | Llama 4                                                                  | T + I<sup>+</sup>                                                   | `meta-llama/Llama-4-Scout-17B-16E-Instruct`, `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`, `meta-llama/Llama-4-Maverick-17B-128E-Instruct` ç­‰ |                        | âœ…                          | âœ…           |
| `LlavaForConditionalGeneration`               | LLaVA-1.5                                                                | T + I<sup>E+</sup>                                                  | `llava-hf/llava-1.5-7b-hf`, `TIGER-Lab/Mantis-8B-siglip-llama3`ï¼ˆè§æ³¨é‡Šï¼‰ç­‰                                  |                        | âœ…                          | âœ…           |
| `LlavaNextForConditionalGeneration`           | LLaVA-NeXT                                                               | T + I<sup>E+</sup>                                                  | `llava-hf/llava-v1.6-mistral-7b-hf`, `llava-hf/llava-v1.6-vicuna-7b-hf` ç­‰                                     |                        | âœ…                          | âœ…           |
| `LlavaNextVideoForConditionalGeneration`      | LLaVA-NeXT-Video                                                         | T + V                                                               | `llava-hf/LLaVA-NeXT-Video-7B-hf` ç­‰                                                                           |                        | âœ…                          | âœ…           |
| `LlavaOnevisionForConditionalGeneration`      | LLaVA-Onevision                                                          | T + I<sup>+</sup> + V<sup>+</sup>                                   | `llava-hf/llava-onevision-qwen2-7b-ov-hf`, `llava-hf/llava-onevision-qwen2-0.5b-ov-hf` ç­‰                     |                        | âœ…                          | âœ…           |
| `MiniCPMO`                                    | MiniCPM-O                                                                | T + I<sup>E+</sup> + V<sup>E+</sup> + A<sup>E+</sup>                | `openbmb/MiniCPM-o-2_6` ç­‰                                                                                     | âœ…                      | âœ…                          | âœ…           |
| `MiniCPMV`                                    | MiniCPM-V                                                                | T + I<sup>E+</sup> + V<sup>E+</sup>                                 | `openbmb/MiniCPM-V-2`ï¼ˆè§æ³¨é‡Šï¼‰ï¼Œ`openbmb/MiniCPM-Llama3-V-2_5`, `openbmb/MiniCPM-V-2_6` ç­‰                   | âœ…                      |                           | âœ…           |
| `MiniMaxVL01ForConditionalGeneration`         | MiniMax-VL                                                               | T + I<sup>E+</sup>                                                  | `MiniMaxAI/MiniMax-VL-01` ç­‰                                                                                   |                        | âœ…                          |                       |
| `Mistral3ForConditionalGeneration`            | Mistral3                                                                 | T + I<sup>+</sup>                                                   | `mistralai/Mistral-Small-3.1-24B-Instruct-2503` ç­‰                                                             | âœ…                      | âœ…                          | âœ…           |
| `MllamaForConditionalGeneration`              | Llama 3.2                                                                | T + I<sup>+</sup>                                                   | `meta-llama/Llama-3.2-90B-Vision-Instruct`, `meta-llama/Llama-3.2-11B-Vision` ç­‰                               |                        |                           |                       |
| `MolmoForCausalLM`                            | Molmo                                                                    | T + I<sup>+</sup>                                                   | `allenai/Molmo-7B-D-0924`, `allenai/Molmo-7B-O-0924` ç­‰                                                       | âœ…                      | âœ…                          | âœ…           |
| `NVLM_D_Model`                                | NVLM-D 1.0                                                               | T + I<sup>+</sup>                                                   | `nvidia/NVLM-D-72B` ç­‰                                                                                        |                        | âœ…                          | âœ…           |
| `Ovis`                                        | Ovis2, Ovis1.6                                                           | T + I<sup>+</sup>                                                   | `AIDC-AI/Ovis2-1B`, `AIDC-AI/Ovis1.6-Llama3.2-3B` ç­‰                                                          |                        | âœ…                          | âœ…           |
| `PaliGemmaForConditionalGeneration`           | PaliGemma, PaliGemma 2                                                   | T + I<sup>E</sup>                                                   | `google/paligemma-3b-pt-224`, `google/paligemma-3b-mix-224`, `google/paligemma2-3b-ft-docci-448` ç­‰           |                        | âœ…                          | âš ï¸           |
| `Phi3VForCausalLM`                            | Phi-3-Vision, Phi-3.5-Vision                                             | T + I<sup>E+</sup>                                                  | `microsoft/Phi-3-vision-128k-instruct`, `microsoft/Phi-3.5-vision-instruct` ç­‰                                 |                        | âœ…                          | âœ…           |
| `Phi4MMForCausalLM`                           | Phi-4-multimodal                                                              | T + I<sup>+</sup> / T + A<sup>+</sup> / I<sup>+</sup> + A<sup>+</sup> | `microsoft/Phi-4-multimmodal-instruct` ç­‰                                                          | âœ…                      | âœ…                                                                                  | âœ…  |
| `PixtralForConditionalGeneration`             | Pixtral                                                                  | T + I<sup>+</sup>                                                   | `mistralai/Mistral-pixtral-12b` ç­‰                                                                |                        | âœ…                          | âœ…           |
| `QwenVLForConditionalGeneration`<sup>^</sup>  | Qwen-VL                                                             | T + I<sup>E+</sup>                                                  | `Qwen/Qwen-VL`, `Qwen/Qwen-VL-Chat` ç­‰                                                                           | âœ…                      | âœ…                          | âœ…            |
| `Qwen2AudioForConditionalGeneration`          | Qwen2-Audio                                                              | T + A<sup>+</sup>                                                   | `Qwen/Qwen2-Audio-7B-Instruct`                                                                                   |                        | âœ…                                                                         | âœ…   |
| `Qwen2VLForConditionalGeneration`             | QVQ, Qwen2-VL                                                              | T + I<sup>E+</sup> + V<sup>E+</sup>           | `Qwen/QVQ-72B-Preview`, `Qwen/Qwen2-VL-7B-Instruct`, `Qwen/Qwen2-VL-72B-Instruct` ç­‰                             | âœ…                      | âœ…                                 | âœ…           |
| `Qwen2_5_VLForConditionalGeneration`          | Qwen2.5-VL                                                               |                                                             | `Qwen/Qwen2.5-VL-3B-Instruct`, `Qwen/Qwen2.5-VL-72B-Instruct` ç­‰                                         | âœ…                      | âœ…                                                                         | âœ…           |
| `Qwen2_5OmniThinkerForConditionalGeneration` | Qwen2.5-Omni                                                                     | T + I<sup>E+</sup> + V<sup>E+</sup> + A<sup>+</sup> | `Qwen/Qwen2.5-Omni-7B`                                                                                   |                        | âœ…                                                                         | âœ…\*         |
| `SkyworkR1VChatModel`                         | Skywork-R1V-38B                                                          | T + I                                                               | `Skywork/Skywork-R1V-38B`                                                                                        |                        | âœ…                          | âœ…           |
| `SmolVLMForConditionalGeneration`             | SmolVLM2                                                                 | T + I                                                               | `SmolVLM2-2.2B-Instruct`                                                                                         | âœ…                      |                           | âœ…           |
| `TarsierForConditionalGeneration`                | Tarsier                                                                  | T + I<sup>E+</sup>                                                  | `omni-search/Tarsier-7b`,`omni-search/Tarsier-34b`                                                               |                        | âœ…                          | âœ…           |

<sup>^</sup> ä½ éœ€è¦é€šè¿‡ `--hf-overrides` è®¾ç½®æ¶æ„åç§°ä»¥åŒ¹é… vLLM ä¸­çš„åç§°ã€‚  
Â Â Â Â â€¢ ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ DeepSeek-VL2 ç³»åˆ—æ¨¡å‹ï¼š  
Â Â Â Â Â Â `--hf-overrides '{"architectures": ["DeepseekVLV2ForCausalLM"]}'`  
<sup>E</sup> æ­¤æ¨¡æ€å¯ä»¥è¾“å…¥é¢„è®¡ç®—çš„åµŒå…¥ã€‚  
<sup>+</sup> æ¯ä¸ªæ–‡æœ¬æç¤ºå¯ä»¥è¾“å…¥å¤šä¸ªé¡¹ç›®ã€‚

!!! warning
    V0 å’Œ V1 éƒ½æ”¯æŒ `Gemma3ForConditionalGeneration` çš„çº¯æ–‡æœ¬è¾“å…¥ã€‚
    ç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤„ç†æ–‡æœ¬ + å›¾åƒè¾“å…¥æ—¶å­˜åœ¨å·®å¼‚ï¼š

    V0 æ­£ç¡®å®ç°äº†æ¨¡å‹çš„æ³¨æ„åŠ›æ¨¡å¼ï¼š
    - å¯¹å¯¹åº”åŒä¸€å›¾åƒçš„å›¾åƒæ ‡è®°ä½¿ç”¨åŒå‘æ³¨æ„åŠ›
    - å¯¹å…¶ä»–æ ‡è®°ä½¿ç”¨å› æœæ³¨æ„åŠ›
    - é€šè¿‡ï¼ˆæœ´ç´ çš„ï¼‰PyTorch SDPA é…åˆæ©ç å¼ é‡å®ç°
    - æ³¨æ„ï¼šå¯¹äºåŒ…å«å›¾åƒçš„é•¿æç¤ºå¯èƒ½ä¼šä½¿ç”¨å¤§é‡å†…å­˜

    V1 ç›®å‰ä½¿ç”¨ç®€åŒ–çš„æ³¨æ„åŠ›æ¨¡å¼ï¼š
    - å¯¹æ‰€æœ‰æ ‡è®°ï¼ˆåŒ…æ‹¬å›¾åƒæ ‡è®°ï¼‰ä½¿ç”¨å› æœæ³¨æ„åŠ›
    - ç”Ÿæˆåˆç†çš„è¾“å‡ºï¼Œä½†ä¸åŸå§‹æ¨¡å‹çš„æ–‡æœ¬ + å›¾åƒè¾“å…¥çš„æ³¨æ„åŠ›æ¨¡å¼ä¸åŒ¹é…ï¼Œç‰¹åˆ«æ˜¯å½“ `{"do_pan_and_scan": true}` æ—¶
    - æœªæ¥å°†æ›´æ–°ä»¥æ”¯æŒæ­£ç¡®çš„è¡Œä¸º

    è¿™ç§é™åˆ¶å­˜åœ¨æ˜¯å› ä¸ºæ¨¡å‹çš„æ··åˆæ³¨æ„åŠ›æ¨¡å¼ï¼ˆå›¾åƒåŒå‘ï¼Œå…¶ä»–å› æœï¼‰å°šæœªè¢« vLLM çš„æ³¨æ„åŠ›åç«¯æ”¯æŒã€‚

!!! note
    ç›®å‰åªæœ‰ä½¿ç”¨ Qwen2.5 æ–‡æœ¬éª¨å¹²çš„ `InternVLChatModel`ï¼ˆå¦‚ `OpenGVLab/InternVL3-2B`ï¼Œ`OpenGVLab/InternVL2.5-1B` ç­‰ï¼‰æ”¯æŒè§†é¢‘è¾“å…¥ã€‚

!!! note
    `h2oai/h2ovl-mississippi-2b` å°†åœ¨ V1 ä¸­å¯ç”¨ï¼Œä¸€æ—¦æˆ‘ä»¬æ”¯æŒå¤´éƒ¨å¤§å°ä¸º 80ã€‚

!!! note
    è¦ä½¿ç”¨ `TIGER-Lab/Mantis-8B-siglip-llama3`ï¼Œä½ éœ€è¦åœ¨è¿è¡Œ vLLM æ—¶ä¼ é€’ `--hf_overrides '{"architectures": ["MantisForConditionalGeneration"]}'`ã€‚

!!! warning
    `AllenAI/Molmo-7B-D-0924` çš„è¾“å‡ºè´¨é‡ï¼ˆç‰¹åˆ«æ˜¯åœ¨å¯¹è±¡å®šä½ä»»åŠ¡ä¸­ï¼‰åœ¨æœ€è¿‘çš„æ›´æ–°ä¸­æœ‰æ‰€ä¸‹é™ã€‚

    ä¸ºè·å¾—æœ€ä½³ç»“æœï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ä»¥ä¸‹ä¾èµ–ç‰ˆæœ¬ï¼ˆåœ¨ A10 å’Œ L40 ä¸Šæµ‹è¯•ï¼‰ï¼š

    ```text
    # æ ¸å¿ƒ vLLM å…¼å®¹ä¾èµ–é¡¹ï¼Œé€‚ç”¨äº Molmo ç²¾åº¦è®¾ç½®ï¼ˆåœ¨ L40 ä¸Šæµ‹è¯•ï¼‰
    torch==2.5.1
    torchvision==0.20.1
    transformers==4.48.1
    tokenizers==0.21.0
    tiktoken==0.7.0
    vllm==0.7.0

    # å¯é€‰ä½†æ¨èç”¨äºæé«˜æ€§èƒ½å’Œç¨³å®šæ€§
    triton==3.1.0
    xformers==0.0.28.post3
    uvloop==0.21.0
    protobuf==5.29.3
    openai==1.60.2
    opencv-python-headless==4.11.0.86
    pillow==10.4.0

    # å·²å®‰è£… FlashAttentionï¼ˆä»…ç”¨äº float16ï¼‰
    flash-attn>=2.5.6  # åœ¨ float32 ä¸­æœªä½¿ç”¨ï¼Œä½†åº”è®°å½•
    ```

    **æ³¨æ„ï¼š** ç¡®ä¿ä½ äº†è§£ä½¿ç”¨è¿‡æ—¶åŒ…çš„å®‰å…¨éšæ‚£ã€‚

!!! note
    å®˜æ–¹çš„ `openbmb/MiniCPM-V-2` å°šä¸å¯ç”¨ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æš‚æ—¶ä½¿ç”¨ä¸€ä¸ªåˆ†æ”¯ï¼ˆ`HwwwH/MiniCPM-V-2`ï¼‰ã€‚
    æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ï¼š<gh-pr:4087#issuecomment-2250397630>

!!! warning
    æˆ‘ä»¬çš„ PaliGemma å®ç°ä¸ Gemma 3ï¼ˆè§ä¸Šæ–‡ï¼‰åœ¨ V0 å’Œ V1 ä¸Šå­˜åœ¨ç›¸åŒçš„é—®é¢˜ã€‚

!!! note
    è¦ä½¿ç”¨ Qwen2.5-Omniï¼Œä½ å¿…é¡»é€šè¿‡ä»¥ä¸‹æ–¹å¼ä»æºä»£ç å®‰è£… Hugging Face Transformers åº“ï¼š
    `pip install git+https://github.com/huggingface/transformers.git`ã€‚

    ä»è§†é¢‘é¢„å¤„ç†ä¸­è¯»å–éŸ³é¢‘ç›®å‰åœ¨ V0 ä¸Šå—æ”¯æŒï¼ˆä½†åœ¨ V1 ä¸Šä¸å—æ”¯æŒï¼‰ï¼Œå› ä¸º V1 å°šæœªæ”¯æŒé‡å æ¨¡æ€ã€‚
    `--mm-processor-kwargs '{"use_audio_in_video": true}'`ã€‚

### æ± åŒ–æ¨¡å‹

æœ‰å…³å¦‚ä½•ä½¿ç”¨æ± åŒ–æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [æ­¤é¡µé¢](./pooling_models.md)ã€‚

!!! warning
    ç”±äºä¸€äº›æ¨¡å‹æ¶æ„åŒæ—¶æ”¯æŒç”Ÿæˆå’Œæ± åŒ–ä»»åŠ¡ï¼Œ
    ä½ åº”æ˜ç¡®æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œä»¥ç¡®ä¿æ¨¡å‹ä»¥æ± åŒ–æ¨¡å¼è€Œä¸æ˜¯ç”Ÿæˆæ¨¡å¼ä½¿ç”¨ã€‚

#### æ–‡æœ¬åµŒå…¥

ä½¿ç”¨ `--task embed` æŒ‡å®šã€‚

ä»»ä½•æ–‡æœ¬ç”Ÿæˆæ¨¡å‹éƒ½å¯ä»¥é€šè¿‡ä¼ é€’ `--task embed` è½¬æ¢ä¸ºåµŒå…¥æ¨¡å‹ã€‚

!!! note
    ä¸ºè·å¾—æœ€ä½³ç»“æœï¼Œä½ åº”ä½¿ç”¨ä¸“é—¨è®­ç»ƒä¸ºæ± åŒ–æ¨¡å‹çš„æ¨¡å‹ã€‚

ä¸‹è¡¨åˆ—å‡ºäº†åœ¨ vLLM ä¸­æµ‹è¯•è¿‡çš„æ¨¡å‹ã€‚

| æ¶æ„                                 | æ¨¡å‹                   | è¾“å…¥     | ç¤ºä¾‹ HF æ¨¡å‹             | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|--------------------------------------|------------------------|----------|--------------------------|------------------------|-----------------------------|
| `LlavaNextForConditionalGeneration`  | åŸºäº LLaVA-NeXT        | T / I    | `royokong/e5-v`          |                        |                             |
| `Phi3VForCausalLM`                   | åŸºäº Phi-3-Vision      | T + I    | `TIGER-Lab/VLM2Vec-Full` | ğŸš§                      | âœ…                           |

#### è½¬å½•

ä½¿ç”¨ `--task transcription` æŒ‡å®šã€‚

ä¸“é—¨ä¸ºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«è®­ç»ƒçš„ Speech2Text æ¨¡å‹ã€‚

| æ¶æ„           | æ¨¡å‹     | ç¤ºä¾‹ HF æ¨¡å‹       | [LoRA][lora-adapter]   | [PP][distributed-serving]   |
|----------------|----------|--------------------|------------------------|-----------------------------|

---

## æ¨¡å‹æ”¯æŒæ”¿ç­–

åœ¨ vLLMï¼Œæˆ‘ä»¬è‡´åŠ›äºä¿ƒè¿›ç¬¬ä¸‰æ–¹æ¨¡å‹åœ¨æˆ‘ä»¬ç”Ÿæ€ç³»ç»Ÿä¸­çš„é›†æˆå’Œæ”¯æŒã€‚æˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨å¹³è¡¡é²æ£’æ€§éœ€æ±‚ä¸æ”¯æŒå¹¿æ³›æ¨¡å‹çš„å®é™…é™åˆ¶ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬ç®¡ç†ç¬¬ä¸‰æ–¹æ¨¡å‹æ”¯æŒçš„æ–¹å¼ï¼š

1. **ç¤¾åŒºé©±åŠ¨æ”¯æŒ**ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºä¸ºæ·»åŠ æ–°æ¨¡å‹åšå‡ºè´¡çŒ®ã€‚å½“ç”¨æˆ·è¯·æ±‚æ”¯æŒæ–°æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æ¬¢è¿ç¤¾åŒºçš„æ‹‰å–è¯·æ±‚ï¼ˆPRï¼‰ã€‚è¿™äº›è´¡çŒ®ä¸»è¦åŸºäºå…¶ç”Ÿæˆè¾“å‡ºçš„åˆç†æ€§è¿›è¡Œè¯„ä¼°ï¼Œè€Œä¸æ˜¯ä¸ç°æœ‰å®ç°ï¼ˆå¦‚ transformersï¼‰çš„ä¸¥æ ¼ä¸€è‡´æ€§ã€‚**è´¡çŒ®å·å¬ï¼š** ç›´æ¥æ¥è‡ªæ¨¡å‹ä¾›åº”å•†çš„ PR éå¸¸å—æ¬¢è¿ï¼

2. **å°½åŠ›ä¿æŒä¸€è‡´æ€§**ï¼šè™½ç„¶æˆ‘ä»¬æ—¨åœ¨ä¿æŒ vLLM ä¸­å®ç°çš„æ¨¡å‹ä¸å…¶ä»–æ¡†æ¶ï¼ˆå¦‚ transformersï¼‰çš„ä¸€å®šä¸€è‡´æ€§ï¼Œä½†å®Œå…¨å¯¹é½å¹¶ä¸æ€»æ˜¯å¯è¡Œçš„ã€‚åŠ é€ŸæŠ€æœ¯å’Œä½ç²¾åº¦è®¡ç®—ç­‰å› ç´ å¯èƒ½å¯¼è‡´å·®å¼‚ã€‚æˆ‘ä»¬æ‰¿è¯ºç¡®ä¿å®ç°çš„æ¨¡å‹åŠŸèƒ½æ­£å¸¸å¹¶äº§ç”Ÿåˆç†çš„ç»“æœã€‚

    !!! tip
        æ¯”è¾ƒ Hugging Face Transformers çš„ `model.generate` è¾“å‡ºä¸ vLLM çš„ `llm.generate` è¾“å‡ºæ—¶ï¼Œè¯·æ³¨æ„ï¼Œå‰è€…ä¼šè¯»å–æ¨¡å‹çš„ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆå³ [generation_config.json](https://github.com/huggingface/transformers/blob/19dabe96362803fb0a9ae7073d03533966598b17/src/transformers/generation/utils.py#L1945)ï¼‰å¹¶åº”ç”¨ç”Ÿæˆé»˜è®¤å‚æ•°ï¼Œè€Œåè€…ä»…ä½¿ç”¨ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°ã€‚æ¯”è¾ƒè¾“å‡ºæ—¶ï¼Œç¡®ä¿æ‰€æœ‰é‡‡æ ·å‚æ•°ç›¸åŒã€‚

3. **é—®é¢˜è§£å†³å’Œæ¨¡å‹æ›´æ–°**ï¼šæˆ‘ä»¬é¼“åŠ±ç”¨æˆ·æŠ¥å‘Šä»–ä»¬åœ¨ç¬¬ä¸‰æ–¹æ¨¡å‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯æˆ–é—®é¢˜ã€‚å»ºè®®çš„ä¿®å¤åº”é€šè¿‡ PR æäº¤ï¼Œå¹¶æ¸…æ¥šè¯´æ˜é—®é¢˜åŠå»ºè®®è§£å†³æ–¹æ¡ˆçš„ç†ç”±ã€‚å¦‚æœä¸€ä¸ªæ¨¡å‹çš„ä¿®å¤å½±å“å¦ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬ä¾èµ–ç¤¾åŒºæ¥å¼ºè°ƒå’Œè§£å†³è¿™äº›è·¨æ¨¡å‹ä¾èµ–ã€‚æ³¨æ„ï¼šå¯¹äºé”™è¯¯ä¿®å¤ PRï¼Œé€šçŸ¥åŸå§‹ä½œè€…ä»¥å¾æ±‚ä»–ä»¬çš„åé¦ˆæ˜¯è‰¯å¥½çš„ç¤¼èŠ‚ã€‚

4. **ç›‘æ§å’Œæ›´æ–°**ï¼šå¯¹ç‰¹å®šæ¨¡å‹æ„Ÿå…´è¶£çš„ç”¨æˆ·åº”ç›‘æ§è¿™äº›æ¨¡å‹çš„æäº¤å†å²ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡è·Ÿè¸ª main/vllm/model_executor/models ç›®å½•ä¸­çš„æ›´æ”¹ï¼‰ã€‚è¿™ç§ä¸»åŠ¨æ–¹æ³•å¸®åŠ©ç”¨æˆ·äº†è§£å¯èƒ½å½±å“ä»–ä»¬ä½¿ç”¨çš„æ¨¡å‹çš„æ›´æ–°å’Œå˜åŒ–ã€‚

5. **é€‰æ‹©æ€§å…³æ³¨**ï¼šæˆ‘ä»¬çš„èµ„æºä¸»è¦ç”¨äºå…·æœ‰é‡å¤§ç”¨æˆ·å…´è¶£å’Œå½±å“çš„æ¨¡å‹ã€‚ä½¿ç”¨é¢‘ç‡è¾ƒä½çš„æ¨¡å‹å¯èƒ½è·å¾—çš„å…³æ³¨è¾ƒå°‘ï¼Œæˆ‘ä»¬ä¾èµ–ç¤¾åŒºåœ¨è¿™äº›æ¨¡å‹çš„ç»´æŠ¤å’Œæ”¹è¿›ä¸­å‘æŒ¥æ›´ç§¯æçš„ä½œç”¨ã€‚

é€šè¿‡è¿™ç§æ–¹æ³•ï¼ŒvLLM è¥é€ äº†ä¸€ä¸ªåä½œç¯å¢ƒï¼Œæ ¸å¿ƒå¼€å‘å›¢é˜Ÿå’Œæ›´å¹¿æ³›çš„ç¤¾åŒºå…±åŒä¸ºæˆ‘ä»¬ç”Ÿæ€ç³»ç»Ÿä¸­æ”¯æŒçš„ç¬¬ä¸‰æ–¹æ¨¡å‹çš„é²æ£’æ€§å’Œå¤šæ ·æ€§åšå‡ºè´¡çŒ®ã€‚

è¯·æ³¨æ„ï¼Œä½œä¸ºæ¨ç†å¼•æ“ï¼ŒvLLM ä¸ä¼šå¼•å…¥æ–°æ¨¡å‹ã€‚å› æ­¤ï¼Œåœ¨è¿™æ–¹é¢ï¼ŒvLLM æ”¯æŒçš„æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ç¬¬ä¸‰æ–¹æ¨¡å‹ã€‚

æˆ‘ä»¬å¯¹æ¨¡å‹æœ‰ä»¥ä¸‹æµ‹è¯•çº§åˆ«ï¼š

1. **ä¸¥æ ¼ä¸€è‡´æ€§**ï¼šæˆ‘ä»¬æ¯”è¾ƒæ¨¡å‹åœ¨è´ªå©ªè§£ç ä¸‹çš„è¾“å‡ºä¸ HuggingFace Transformers åº“ä¸­æ¨¡å‹çš„è¾“å‡ºã€‚è¿™æ˜¯æœ€é«˜çº§åˆ«çš„æµ‹è¯•ã€‚è¯·å‚é˜… [æ¨¡å‹æµ‹è¯•](https://github.com/vllm-project/vllm/blob/main/tests/models) ä»¥äº†è§£é€šè¿‡æ­¤æµ‹è¯•çš„æ¨¡å‹ã€‚
2. **è¾“å‡ºåˆç†æ€§**ï¼šæˆ‘ä»¬æ£€æŸ¥æ¨¡å‹çš„è¾“å‡ºæ˜¯å¦åˆç†å’Œè¿è´¯ï¼Œé€šè¿‡æµ‹é‡è¾“å‡ºçš„å›°æƒ‘åº¦å’Œæ£€æŸ¥ä»»ä½•æ˜æ˜¾é”™è¯¯ã€‚è¿™æ˜¯ä¸€ä¸ªè¾ƒä½çº§åˆ«çš„æµ‹è¯•ã€‚
3. **è¿è¡Œæ—¶åŠŸèƒ½**ï¼šæˆ‘ä»¬æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ä»¥åŠ è½½å¹¶æ— é”™è¯¯è¿è¡Œã€‚è¿™æ˜¯æœ€ä½çº§åˆ«çš„æµ‹è¯•ã€‚è¯·å‚é˜… [åŠŸèƒ½æµ‹è¯•](gh-dir:tests) å’Œ [ç¤ºä¾‹](gh-dir:examples) ä»¥äº†è§£é€šè¿‡æ­¤æµ‹è¯•çš„æ¨¡å‹ã€‚
4. **ç¤¾åŒºåé¦ˆ**ï¼šæˆ‘ä»¬ä¾é ç¤¾åŒºæä¾›æ¨¡å‹çš„åé¦ˆã€‚å¦‚æœæ¨¡å‹å‡ºç°æ•…éšœæˆ–æœªæŒ‰é¢„æœŸå·¥ä½œï¼Œæˆ‘ä»¬é¼“åŠ±ç”¨æˆ·æå‡ºé—®é¢˜æŠ¥å‘Šæˆ–æäº¤æ‹‰å–è¯·æ±‚ä¿®å¤ã€‚å…¶ä½™æ¨¡å‹å±äºæ­¤ç±»åˆ«ã€‚