# 自动前缀缓存

前缀缓存键值缓存（KV-cache）块是大型语言模型（LLM）推理中一种常见的优化方法，以避免重复计算提示内容。其核心思想很简单——我们缓存已处理请求的键值缓存块，并在新请求与先前请求具有相同前缀时重用这些块。由于前缀缓存几乎是“免费的午餐”且不会改变模型输出，它已被许多公共端点（例如，OpenAI、Anthropic 等）以及大多数开源 LLM 推理框架（例如，SGLang）广泛使用。

虽然实现前缀缓存的方式有很多种，vLLM 选择了一种基于哈希的方法。具体来说，我们通过块中的标记（tokens）以及块之前的前缀标记对每个键值缓存块进行哈希：

```text
                    块 1                  块 2                  块 3
         [一阵微风吹动] [树叶，孩子们] [在远处欢笑]
块 1: |<--- 块标记 ---->|
块 2: |<------- 前缀 ------>| |<--- 块标记 --->|
块 3: |<------------------ 前缀 -------------------->| |<--- 块标记 ---->|
```

在上面的例子中，第一个块的键值缓存可以通过标记“一阵微风吹动”唯一标识。第三个块可以通过块中的标记“在远处欢笑”以及前缀标记“一阵微风吹动树叶，孩子们”唯一标识。因此，我们可以构建块哈希 `hash(tuple[components])`，其中 components 包括：

* 父哈希值：父块的哈希值。
* 块标记：该块中的标记元组。包含确切标记的原因是为了减少潜在的哈希值冲突。
* 额外哈希：其他用于使该块唯一的值，例如 LoRA ID、多模态输入哈希（见下面的例子），以及用于多租户环境中隔离缓存的缓存盐。

> **注意 1：** 我们只缓存完整的块。

> **注意 2：** 上述哈希键结构并非 100% 无冲突。理论上，不同的前缀标记仍可能具有相同的哈希值。为了在多租户环境中避免哈希冲突，**我们建议使用 SHA256** 作为哈希函数，而不是默认的内置哈希。SHA256 从 vLLM v0.8.3 开始支持，必须通过命令行参数启用。它会带来大约每标记 100-200 纳秒的性能影响（对于 50k 标记的上下文约为 6 毫秒）。

**多模态输入的哈希示例**  
在此示例中，我们展示前缀缓存如何处理多模态输入（例如，图像）。假设我们有一个包含以下消息的请求：

```text
messages = [
    {"role": "user",
     "content": [
         {"type": "text",
          "text": "这张图片里有什么？"
         },
         {"type": "image_url",
          "image_url": {"url": image_url},
         },
    ]},
]
```

它将变成以下提示：

```text
提示：
    <s>[INST]这张图片里有什么？\n[IMG][/INST]

标记化提示：
    [1, 3, 7493, 1681, 1294, 1593, 3937, 9551, 10, 4]

带占位符的提示（<P>）：
    [1, 3, 7493, 1681, 1294, 1593, 3937, 9551, <P>, <P>, ..., <P>, 4]
```

如我们所见，标记化后，`[IMG]` 将被替换为一系列占位符标记，这些占位符在预填充期间将被图像嵌入替换。前缀缓存支持此情况的挑战在于我们需要区分图像和占位符。为了解决这个问题，我们对前端图像处理器生成的图像哈希进行编码。例如，上述提示中块的哈希如下（假设块大小为 16，且有 41 个占位符标记）：

```text
块 0
    父哈希：无
    标记 ID：1, 3, 7493, 1681, 1294, 1593, 3937, 9551, <p>, ..., <p>
    额外哈希：<图像哈希>
块 1
    父哈希：块 0 哈希
    标记 ID：<p>, ..., <p>
    额外哈希：<图像哈希>
块 2
    父哈希：块 1 哈希
    标记 ID：<p>, ..., <p>
    额外哈希：<图像哈希>
块 3
    父哈希：块 2 哈希
    标记 ID：<p>, ..., <p>, 4
    额外哈希：<图像哈希>
```

在本文档的其余部分，我们首先介绍 vLLM v1 中用于前缀缓存的数据结构，然后介绍主要键值缓存操作（例如分配、追加、释放、驱逐）的前缀缓存工作流程。最后，我们通过一个示例说明端到端的前缀缓存工作流程。

**缓存隔离以确保安全性**  
为了在共享环境中提高隐私性，vLLM 支持通过可选的每请求加盐来隔离前缀缓存重用。通过在请求中包含 `cache_salt`，该值会被注入到第一个块的哈希中，确保只有具有相同盐的请求可以重用缓存的键值块。这可以防止基于时间的攻击，攻击者可能通过观察延迟差异推断缓存内容。这在不影响性能的情况下提供了保护。

```json
{
  "messages": [
    {"role": "system", "content": "你是一个有用的助手。"},
    {"role": "user", "content": "这是一份包含世界系列赛详细信息的文档：..."},
    {"role": "user", "content": "2020 年世界系列赛谁赢了？"}
  ],
  "cache_salt": "你的缓存盐"
}
```

通过这种设置，缓存共享仅限于明确同意使用相同盐的用户或请求，从而在信任组内启用缓存重用，同时隔离其他用户。

> **注意：** 缓存隔离在引擎 V0 中不支持。

## 数据结构

vLLM v1 中的前缀缓存是在键值缓存管理器中实现的。基本构建块是“Block”数据类（简化版）：

```python
class KVCacheBlock:
    # 块 ID（不可变）
    block_id: int
    # 块哈希（当块满时分配，当块被驱逐时重置）。
    block_hash: BlockHash
    # 当前使用该块的请求数。
    ref_cnt: int

    # 用于形成空闲队列双向链表的指针。
    prev_free_block: Optional["KVCacheBlock"] = None
    next_free_block: Optional["KVCacheBlock"] = None
```

有两个设计要点需要强调：

1. 在初始化键值缓存管理器时，我们分配所有 KVCacheBlock 作为一个块池。这避免了 Python 对象创建的开销，并可以轻松跟踪所有块的状态。  
2. 我们在 KVCacheBlock 中直接引入双向链表指针，以便直接构建空闲队列。这带来两个好处：  
   1. 我们可以在 O(1) 复杂度的条件下将中间元素移动到队列尾部。  
   2. 我们可以避免引入另一个 Python 队列（例如，`deque`），后者会对元素进行包装。

因此，在键值缓存管理器初始化时，我们将拥有以下组件：

![组件概述](../../assets/design/v1/prefix_caching/overview.png)

* 块池：KVCacheBlock 列表。  
* 空闲块队列：仅存储头部和尾部块的指针以进行操作。  
* 缓存块：从哈希键到块 ID 的映射。  
* 请求块：从请求 ID 到分配的块 ID 的映射。

## 操作

### 块分配

**新请求：** 调度程序为新请求分配键值缓存块的工作流程：

1. 调度程序调用 `kv_cache_manager.get_computed_blocks()` 获取已计算的块序列。这是通过对请求中的提示标记进行哈希并查找缓存块来完成的。  
2. 调度程序调用 `kv_cache_manager.allocate_slots()`，执行以下步骤：  
   1. 计算所需的新块数量，如果没有足够的块可分配，则返回。  
   2. “触碰”已计算的块。增加已计算块的引用计数，如果该块未被其他请求使用，则将其从空闲队列中移除。这是为了避免这些已计算块被驱逐。参见下一节的示例以进行说明。  
   3. 通过弹出空闲队列的头部来分配新块。如果头部块是缓存块，这也将“驱逐”该块，使其无法被其他请求重用。  
   4. 如果分配的块已满，我们立即将其添加到缓存块中，以便在同一批次中的其他请求可以重用该块。

**运行中的请求：** 调度程序为运行中的请求分配键值缓存块的工作流程：

1. 调度程序调用 `kv_cache_manager.append_slots()`，执行以下步骤：  
   1. 计算所需的新块数量，如果没有足够的块可分配，则返回。  
   2. 通过弹出空闲队列的头部来分配新块。如果头部块是缓存块，这也将“驱逐”该块，使其无法被其他请求重用。  
   3. 将标记 ID 追加到现有块和新块的槽中。如果一个块已满，我们将其添加到缓存块中以进行缓存。

**重复块**  
假设块大小为 4，你发送一个请求（请求 1）包含提示 ABCDEF 和解码长度 3：

```text
提示：[A, B, C, D, E, F]
输出：[G, H, I]

时间 0：
  标记：[A, B, C, D, E, F, G]
  块表：[0 (ABCD), 1 (EFG)]
  缓存块：0
时间 1：
  标记：[A, B, C, D, E, F, G, H]
  块表：[0 (ABCD), 1 (EFGH)]
  缓存块：0, 1
时间 2：
  标记：[A, B, C, D, E, F, G, H, I]
  块表：[0 (ABCD), 1 (EFGH), 2 (I)]
  缓存块：0, 1
```

现在块 0 和块 1 已缓存，我们再次发送相同的请求（请求 2），使用贪婪采样，因此它将产生与请求 1 完全相同的输出：

```text
提示：[A, B, C, D, E, F]
输出：[G, H, I]

时间 0：
  标记：[A, B, C, D, E, F, G]
  块表：[0 (ABCD), 3 (EFG)]
  缓存块：0, 1
时间 1：
  标记：[A, B, C, D, E, F, G, H]
  块表：[0 (ABCD), 3 (EFGH)]
  缓存块：0, 1, 3
```

如上所示，块 3 是一个新的完整块并被缓存。然而，它与块 1 是冗余的，意味着我们对同一个块缓存了两次。在 v0 中，当检测到块 3 是重复的时，我们会释放块 3 并让请求 2 使用块 1，因此在时间 1 的块表变为 `[0, 1]`。然而，在 vLLM v1 中，块表是仅追加的，这意味着不允许将块表从 `[0, 3]` 更改为 `[0, 1]`。因此，我们将为哈希键 E-H 拥有重复的块。这种重复将在请求被释放时消除。

### 释放

当一个请求完成后，如果没有其他请求在使用这些块（引用计数 = 0），我们会释放所有相关块。在本例中，我们释放请求 1 以及与其关联的块 2、3、4、8。我们可以看到，释放的块以*逆序*添加到空闲队列的尾部。这是因为请求的最后一个块必须哈希更多标记，且被其他请求重用的可能性较低，因此应优先被驱逐。

![请求释放后的空闲队列](../../assets/design/v1/prefix_caching/free.png)

### 驱逐（LRU）

当空闲队列的头部块（最近最少使用的块）是缓存块时，我们必须驱逐该块以防止其被其他请求使用。具体来说，驱逐包括以下步骤：

1. 从空闲队列的头部弹出块。这是将被驱逐的最近最少使用块。  
2. 从缓存块中移除块 ID。  
3. 移除块哈希。

## 示例

在此示例中，我们假设块大小为 4（每个块可以缓存 4 个标记），键值缓存管理器中总共有 10 个块。

**时间 1：缓存为空，来了一个新请求。** 我们分配 4 个块。其中 3 个块已满并被缓存。第四个块部分填充，只有 3 个标记。

![示例时间 1](../../assets/design/v1/prefix_caching/example-time-1.png)

**时间 3：请求 0 使块 3 满，并请求一个新块以继续解码。** 我们缓存块 3 并分配块 4。

![示例时间 3](../../assets/design/v1/prefix_caching/example-time-3.png)

**时间 4：请求 1 到来，包含 14 个提示标记，其中前 10 个标记与请求 0 相同。** 我们可以看到，只有前 2 个块（8 个标记）命中缓存，因为第 3 个块只有 2 个标记匹配。

![示例时间 4](../../assets/design/v1/prefix_caching/example-time-4.png)

**时间 5：请求 0 完成并释放。** 块 2、3 和 4 以逆序添加到空闲队列（但块 2 和 3 仍被缓存）。块 0 和 1 未被添加到空闲队列，因为它们正被请求 1 使用。

![示例时间 5](../../assets/design/v1/prefix_caching/example-time-5.png)

**时间 6：请求 1 完成并释放。**

![示例时间 6](../../assets/design/v1/prefix_caching/example-time-6.png)

**时间 7：请求 2 到来，包含 29 个提示标记，其中前 12 个标记与请求 0 相同。** 注意，尽管空闲队列中的块顺序为 `7 - 8 - 9 - 4 - 3 - 2 - 6 - 5 - 1 - 0`，但缓存命中的块（即 0、1、2）在分配前被触碰并从队列中移除，因此空闲队列变为 `7 - 8 - 9 - 4 - 3 - 6 - 5`。因此，分配的块为 0（缓存）、1（缓存）、2（缓存）、7、8、9、4、3（被驱逐）。

![示例时间 7](../../assets/design/v1/prefix_caching/example-time-7.png)